/var/spool/slurmd/job5382651/slurm_script: line 16: cd: /dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/projects/statial_omics/autostainer_study/: No such file or directory
GPU available: True, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/dartfs-hpc/rc/home/x/f006jnx/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1814: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.
  rank_zero_warn(
/dartfs-hpc/rc/home/x/f006jnx/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/dartfs-hpc/rc/home/x/f006jnx/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

  | Name              | Type             | Params
-------------------------------------------------------
0 | image_to_features | FeatureExtractor | 22.8 M
1 | features_to_genes | FeaturesToGenes  | 9.2 M 
-------------------------------------------------------
32.0 M    Trainable params
0         Non-trainable params
32.0 M    Total params
128.158   Total estimated model params size (MB)
/dartfs-hpc/rc/home/x/f006jnx/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/dartfs-hpc/rc/home/x/f006jnx/anaconda3/lib/python3.8/site-packages/PIL/Image.py:3035: DecompressionBombWarning: Image size (178781337 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
/dartfs-hpc/rc/home/x/f006jnx/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
slurmstepd: error: *** JOB 5382651 ON gv01 CANCELLED AT 2022-12-06T09:10:56 DUE TO TIME LIMIT ***
